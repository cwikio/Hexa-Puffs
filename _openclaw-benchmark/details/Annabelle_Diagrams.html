<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Annabelle Architecture Diagrams</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 24px;
            background: #f8f9fa;
            color: #2c3e50;
        }
        h1 {
            color: #1a5276;
            border-bottom: 3px solid #1a5276;
            padding-bottom: 12px;
        }
        h2 {
            color: #2c3e50;
            margin-top: 48px;
        }
        .subtitle {
            color: #7f8c8d;
            font-size: 14px;
            margin-top: -8px;
        }
        .diagram-container {
            background: white;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 24px;
            margin: 24px 0;
            overflow-x: auto;
        }
        .mermaid {
            display: flex;
            justify-content: center;
        }
        .description {
            background: #eaf2f8;
            border-left: 4px solid #2980b9;
            padding: 16px;
            margin: 16px 0;
            border-radius: 0 4px 4px 0;
            font-size: 14px;
            line-height: 1.6;
        }
        .legend {
            display: flex;
            flex-wrap: wrap;
            gap: 12px;
            margin: 16px 0;
        }
        .legend-item {
            display: flex;
            align-items: center;
            gap: 6px;
            font-size: 13px;
        }
        .legend-color {
            width: 16px;
            height: 16px;
            border-radius: 3px;
            border: 1px solid #666;
        }
    </style>
</head>
<body>
    <h1>Annabelle Architecture Diagrams</h1>
    <p class="subtitle">Prepared for Tomasz Cwik — February 2026</p>

    <h2>1. Decision-Making Flowchart</h2>
    <div class="description">
        <p>Shows every decision point from message arrival to response delivery. The flow has three layers: <strong>Orchestrator routing</strong> (slash commands, Guardian scanning, agent dispatch), <strong>Thinker agent loop</strong> (context building, tool selection, LLM reasoning), and <strong>tool execution pipeline</strong> (ToolRouter, Guardian input/output scanning, MCP execution).</p>
        <p>Key architectural feature: tool calls leave the Thinker entirely, passing through the Orchestrator's HTTP API where Guardian can scan both inputs and outputs. This stop-call-resume pattern trades latency for security.</p>
    </div>
    <div class="legend">
        <div class="legend-item"><div class="legend-color" style="background:#D6EAF8"></div> Inbound / Dispatch</div>
        <div class="legend-item"><div class="legend-color" style="background:#FADBD8"></div> Rejection paths</div>
        <div class="legend-item"><div class="legend-color" style="background:#E8DAEF"></div> LLM reasoning loop</div>
        <div class="legend-item"><div class="legend-color" style="background:#FEF9E7"></div> Tool execution</div>
        <div class="legend-item"><div class="legend-color" style="background:#D5F5E3"></div> Successful delivery</div>
    </div>
    <div class="diagram-container">
        <pre class="mermaid">
flowchart TD
    A["Inbound Message<br/>(Telegram via MTProto polling)"] --> B["Orchestrator<br/>ChannelManager receives message"]
    B --> C{"Slash<br/>Command?"}
    C -->|Yes| D["SlashCommandHandler<br/>/status, /logs, /kill, /security, /cron..."]
    D --> E["RESPONSE SENT<br/>Direct to Telegram"]
    C -->|No| F{"Guardian<br/>Input Scan?"}
    F -->|Blocked| G["BLOCKED<br/>Prompt injection detected"]
    F -->|Allowed| H{"Agent<br/>Paused?"}
    H -->|Yes| I["BLOCKED<br/>Cost controls active"]
    H -->|No| J["AgentManager<br/>Lazy-spawn Thinker if needed"]
    J --> K["Dispatch to Thinker<br/>POST /process-message"]

    K --> L["Phase 1: Build Context<br/>Persona + Profile + Memories<br/>+ Playbooks + Date/Time"]
    L --> M["Phase 2: Select Tools<br/>Embedding + Regex merge<br/>(capped at 25 tools)"]
    M --> N["Phase 3: LLM Reasoning<br/>Groq / LM Studio / Ollama<br/>via Vercel AI SDK"]

    N --> O{"Tool Call<br/>in Response?"}
    O -->|No| P{"Model<br/>Done?"}
    P -->|No| N
    P -->|Yes| Q{"Hallucination<br/>Detected?"}
    Q -->|Yes| R["Retry with<br/>toolChoice: required<br/>temp capped at 0.3"]
    R --> N
    Q -->|No| S["Phase 4: Save Session<br/>Append to JSONL"]
    S --> T["Phase 5: Record Cost<br/>Sliding window monitor"]
    T --> U["Schedule Fact Extraction<br/>5-min idle timer"]
    U --> V["RESPONSE DELIVERED<br/>via Telegram MCP"]

    O -->|Yes| W["Normalize Args<br/>coerce booleans, strip nulls<br/>inject chat_id"]
    W --> X["POST /tools/call<br/>Orchestrator HTTP API"]
    X --> Y["ToolRouter<br/>Strip prefix → resolve MCP"]
    Y --> Z{"Guardian<br/>Scans Tool?"}
    Z -->|Input scan| AA["Guardian scan_content<br/>on args"]
    AA -->|Blocked| AB["SecurityError<br/>Tool never executes"]
    AB --> N
    AA -->|Allowed| AC["MCP Executes Tool<br/>(stdio child process)"]
    Z -->|No scan| AC
    AC --> AD{"Guardian<br/>Output Scan?"}
    AD -->|Scan| AE["Guardian scan_content<br/>on result"]
    AE -->|Blocked| AF["SecurityError<br/>Result discarded"]
    AF --> N
    AE -->|Allowed| AG["Result → Thinker<br/>LLM continues with result"]
    AD -->|No scan| AG
    AG --> N

    style A fill:#D6EAF8,stroke:#2C3E50,color:#000
    style E fill:#E8DAEF,stroke:#6C3483,color:#000
    style G fill:#FADBD8,stroke:#C0392B,color:#000
    style I fill:#FADBD8,stroke:#C0392B,color:#000
    style AB fill:#FADBD8,stroke:#C0392B,color:#000
    style AF fill:#FADBD8,stroke:#C0392B,color:#000
    style V fill:#D5F5E3,stroke:#1E8449,color:#000
    style K fill:#D6EAF8,stroke:#154360,color:#000
    style N fill:#E8DAEF,stroke:#6C3483,color:#000
    style AC fill:#FEF9E7,stroke:#D68910,color:#000
    style AG fill:#FEF9E7,stroke:#D68910,color:#000
        </pre>
    </div>

    <h2>2. Waterfall Sequence Diagram</h2>
    <div class="description">
        <p>Shows the temporal flow across all ten system components. The blue-shaded rectangle is the <strong>Thinker Agent Loop</strong> — where context building, tool selection, LLM reasoning, and session persistence happen.</p>
        <p>The <strong>loop</strong> block inside the agent loop shows the reasoning cycle: LLM generates, tool calls are intercepted, sent through the Orchestrator (with Guardian scanning at both ends), and results fed back. This continues until the model signals completion or maxSteps is reached.</p>
    </div>
    <div class="diagram-container">
        <pre class="mermaid">
sequenceDiagram
    autonumber
    participant U as User
    participant TG as Telegram MCP
    participant O as Orchestrator (:8010)
    participant G as Guardian
    participant AM as AgentManager
    participant TH as Thinker (:8006)
    participant MEM as Memorizer (SQLite)
    participant LLM as LLM Provider
    participant TR as ToolRouter
    participant MCP as Target MCP

    U->>TG: Send message via Telegram
    Note over TG: MTProto protocol
    O->>TG: Poll get_new_messages (10s interval)
    TG-->>O: New message payload

    Note over O: Slash command check
    O->>O: SlashCommandHandler.match()

    O->>G: Input scan (if enabled)
    G-->>O: Allowed / Blocked

    O->>AM: Check agent status
    AM-->>O: Running / Paused / Stopped
    Note over AM: Lazy-spawn if stopped

    O->>TH: POST /process-message

    rect rgb(235, 245, 255)
        Note over TH,MCP: Thinker Agent Loop

        TH->>MEM: get_profile + retrieve_memories
        MEM-->>TH: Profile + top 5 facts

        TH->>TH: Build context (6 layers)
        Note over TH: Persona + Profile + Memories + Playbooks + Date + Chat ID

        TH->>TH: Select tools
        Note over TH: Embedding + Regex merge OR required_tools direct (capped at 25)

        TH->>TH: Inject sticky tools (last 3 turns)

        TH->>LLM: generateText() with system prompt + tools
        loop Reasoning Steps (maxSteps=8)
            LLM-->>TH: Response (text or tool calls)
            alt Tool call in response
                TH->>TH: Normalize args (coerce, strip, inject)
                TH->>O: POST /tools/call
                O->>TR: Resolve prefixed name
                TR->>G: Input scan (per-MCP config)
                G-->>TR: Allowed
                TR->>MCP: Execute original tool name
                Note over MCP: Stdio child process
                MCP-->>TR: Tool result
                TR->>G: Output scan (per-MCP config)
                G-->>TR: Allowed
                TR-->>O: Result
                O-->>TH: Tool result
                TH->>LLM: Feed result for next step
            end
        end

        Note over TH: Check for hallucination
        TH->>TH: Record token usage (CostMonitor)
        TH->>TH: Save turn to session JSONL
        TH->>TH: Schedule fact extraction (5-min timer)
    end

    TH-->>O: Response + toolsUsed + tokens
    O->>TG: telegram_send_message
    TG-->>U: Delivery confirmation
        </pre>
    </div>

    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'default',
            securityLevel: 'loose',
            flowchart: { useMaxWidth: true, htmlLabels: true },
            sequence: { useMaxWidth: true, showSequenceNumbers: true }
        });
    </script>
</body>
</html>
